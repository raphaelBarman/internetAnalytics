{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** R\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Raphael Strebel\n",
    "* Raphaël Barman\n",
    "* Thierry Bossy\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import load_pkl\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "id2name = np.load('id2name.npy').item()\n",
    "name2id = np.load('name2id.npy').item()\n",
    "idx2Term = np.load('idx2Term.npy').item()\n",
    "term2Idx = np.load('term2Idx.npy').item()\n",
    "idx2Course = np.load('idx2Course.npy').item()\n",
    "course2Idx = np.load('course2Idx.npy').item()\n",
    "\n",
    "numTerms = len(term2Idx.keys())\n",
    "numCourses = len(course2Idx.keys())\n",
    "\n",
    "bagOfWords = np.load('bagOfWords.npy').item()\n",
    "\n",
    "stopwords = load_pkl('data/stopwords.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We construct a matrix of sparse vectors with the column being the index of the course\n",
    "# and the row being the term, the value is the count of the term in the course.\n",
    "courses = sc.parallelize(course2Idx.keys())\n",
    "def course_vector(course):\n",
    "    id = course2Idx[course]\n",
    "    counts = {}\n",
    "    for term in bagOfWords[course]:\n",
    "        counts[term2Idx[term]] = bagOfWords[course][term]\n",
    "    counts = sorted(counts.items())\n",
    "    keys = [x[0] for x in counts]\n",
    "    values = [x[1] for x in counts]\n",
    "    return (id, Vectors.sparse(numTerms, keys, values))\n",
    "courses = courses.map(course_vector).map(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "   - algorithm\t0.017\n",
      "   - programming\t0.015\n",
      "   - problem\t0.012\n",
      "   - structure\t0.011\n",
      "   - computer\t0.010\n",
      "   - software\t0.010\n",
      "   - material\t0.009\n",
      "   - quantum\t0.009\n",
      "   - tool\t0.009\n",
      "   - communication\t0.009\n",
      "Topic #2\n",
      "   - optical\t0.015\n",
      "   - optic\t0.014\n",
      "   - image\t0.013\n",
      "   - material\t0.013\n",
      "   - microscopy\t0.012\n",
      "   - imaging\t0.011\n",
      "   - electron\t0.010\n",
      "   - processing\t0.009\n",
      "   - principle\t0.007\n",
      "   - technique\t0.006\n",
      "Topic #3\n",
      "   - chemical\t0.017\n",
      "   - biology\t0.015\n",
      "   - molecular\t0.014\n",
      "   - protein\t0.012\n",
      "   - engineering\t0.011\n",
      "   - reaction\t0.010\n",
      "   - interaction\t0.008\n",
      "   - process\t0.008\n",
      "   - cell\t0.008\n",
      "   - biological\t0.007\n",
      "Topic #4\n",
      "   - modeling\t0.013\n",
      "   - information\t0.010\n",
      "   - presentation\t0.009\n",
      "   - innovation\t0.008\n",
      "   - strategy\t0.008\n",
      "   - work\t0.008\n",
      "   - business\t0.008\n",
      "   - tool\t0.007\n",
      "   - plan\t0.007\n",
      "   - class\t0.007\n",
      "Topic #5\n",
      "   - report\t0.029\n",
      "   - skill\t0.018\n",
      "   - scientific\t0.017\n",
      "   - plan\t0.016\n",
      "   - research\t0.015\n",
      "   - written\t0.013\n",
      "   - paper\t0.013\n",
      "   - ass\t0.011\n",
      "   - risk\t0.011\n",
      "   - experiment\t0.011\n",
      "Topic #6\n",
      "   - theory\t0.020\n",
      "   - linear\t0.018\n",
      "   - problem\t0.013\n",
      "   - probability\t0.011\n",
      "   - exam\t0.011\n",
      "   - equation\t0.010\n",
      "   - signal\t0.009\n",
      "   - stochastic\t0.009\n",
      "   - introduction\t0.008\n",
      "   - statistical\t0.008\n",
      "Topic #7\n",
      "   - energy\t0.025\n",
      "   - circuit\t0.017\n",
      "   - power\t0.013\n",
      "   - sensor\t0.013\n",
      "   - technology\t0.009\n",
      "   - device\t0.008\n",
      "   - control\t0.007\n",
      "   - electrical\t0.007\n",
      "   - integrated\t0.007\n",
      "   - principle\t0.007\n",
      "Topic #8\n",
      "   - cell\t0.015\n",
      "   - material\t0.014\n",
      "   - flow\t0.014\n",
      "   - application\t0.013\n",
      "   - property\t0.011\n",
      "   - mass\t0.010\n",
      "   - heat\t0.010\n",
      "   - device\t0.009\n",
      "   - transfer\t0.009\n",
      "   - laser\t0.008\n",
      "Topic #9\n",
      "   - process\t0.018\n",
      "   - chemistry\t0.017\n",
      "   - control\t0.012\n",
      "   - water\t0.010\n",
      "   - environmental\t0.009\n",
      "   - reactor\t0.008\n",
      "   - chemical\t0.008\n",
      "   - engineering\t0.008\n",
      "   - treatment\t0.008\n",
      "   - reaction\t0.008\n",
      "Topic #10\n",
      "   - group\t0.014\n",
      "   - work\t0.012\n",
      "   - presentation\t0.011\n",
      "   - semester\t0.010\n",
      "   - development\t0.008\n",
      "   - study\t0.008\n",
      "   - plan\t0.007\n",
      "   - social\t0.007\n",
      "   - activity\t0.007\n",
      "   - oral\t0.007\n"
     ]
    }
   ],
   "source": [
    "model = LDA.train(courses,k=10,seed=1)\n",
    "for idx, topics in enumerate(model.describeTopics(10)):\n",
    "    print('Topic #%d'%(idx+1))\n",
    "    for termIdx, term in enumerate(topics[0]):\n",
    "        print('   - %s\\t%.3f'%(idx2Term[term],topics[1][termIdx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Algorithmics\n",
    "2. Optics\n",
    "3. Bio-chemistry\n",
    "4. Statistical finances\n",
    "5. Research\n",
    "6. Probability and statistics\n",
    "7. Electrical engineering\n",
    "8. Materials Science and Engineering\n",
    "9. Environmental science\n",
    "10. Projects\n",
    "\n",
    "Reminder of LSI:\n",
    "1. Research\n",
    "2. Laboratory\n",
    "3. Finances\n",
    "4. Architecture\n",
    "5. Bio economy \n",
    "6. Microscopy\n",
    "7. Life science\n",
    "8. Micro technology\n",
    "9. Biomechanics\n",
    "10. Cultural Heritage\n",
    "\n",
    "It looks similar for some, but most of the time, the terms in the topics are more precise and related to their subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 1.01\n",
      "   Topic #1\n",
      "      - algorithm\t0.016\n",
      "      - programming\t0.015\n",
      "      - problem\t0.013\n",
      "      - theory\t0.011\n",
      "      - optimization\t0.010\n",
      "   Topic #2\n",
      "      - material\t0.015\n",
      "      - optical\t0.013\n",
      "      - optic\t0.013\n",
      "      - image\t0.012\n",
      "      - microscopy\t0.011\n",
      "   Topic #3\n",
      "      - chemical\t0.015\n",
      "      - biology\t0.013\n",
      "      - molecular\t0.013\n",
      "      - protein\t0.012\n",
      "      - cell\t0.012\n",
      "   Topic #4\n",
      "      - research\t0.009\n",
      "      - presentation\t0.009\n",
      "      - innovation\t0.008\n",
      "      - work\t0.008\n",
      "      - plan\t0.008\n",
      "   Topic #5\n",
      "      - report\t0.024\n",
      "      - skill\t0.015\n",
      "      - risk\t0.014\n",
      "      - plan\t0.014\n",
      "      - scientific\t0.013\n",
      "   Topic #6\n",
      "      - linear\t0.016\n",
      "      - theory\t0.015\n",
      "      - problem\t0.011\n",
      "      - control\t0.010\n",
      "      - probability\t0.010\n",
      "   Topic #7\n",
      "      - energy\t0.022\n",
      "      - circuit\t0.017\n",
      "      - sensor\t0.012\n",
      "      - power\t0.011\n",
      "      - device\t0.010\n",
      "   Topic #8\n",
      "      - flow\t0.013\n",
      "      - cell\t0.013\n",
      "      - heat\t0.011\n",
      "      - mass\t0.010\n",
      "      - equation\t0.010\n",
      "   Topic #9\n",
      "      - chemistry\t0.020\n",
      "      - process\t0.012\n",
      "      - reaction\t0.010\n",
      "      - chemical\t0.010\n",
      "      - organic\t0.010\n",
      "   Topic #10\n",
      "      - group\t0.011\n",
      "      - engineering\t0.009\n",
      "      - presentation\t0.009\n",
      "      - work\t0.007\n",
      "      - process\t0.007\n",
      "For alpha = 5.00\n",
      "   Topic #1\n",
      "      - algorithm\t0.018\n",
      "      - programming\t0.015\n",
      "      - problem\t0.013\n",
      "      - structure\t0.012\n",
      "      - communication\t0.012\n",
      "   Topic #2\n",
      "      - optical\t0.015\n",
      "      - material\t0.014\n",
      "      - optic\t0.014\n",
      "      - image\t0.014\n",
      "      - microscopy\t0.012\n",
      "   Topic #3\n",
      "      - chemical\t0.017\n",
      "      - biology\t0.015\n",
      "      - molecular\t0.015\n",
      "      - protein\t0.012\n",
      "      - cell\t0.012\n",
      "   Topic #4\n",
      "      - modeling\t0.012\n",
      "      - research\t0.010\n",
      "      - information\t0.009\n",
      "      - presentation\t0.008\n",
      "      - innovation\t0.008\n",
      "   Topic #5\n",
      "      - report\t0.030\n",
      "      - skill\t0.020\n",
      "      - plan\t0.017\n",
      "      - scientific\t0.017\n",
      "      - written\t0.014\n",
      "   Topic #6\n",
      "      - linear\t0.019\n",
      "      - theory\t0.019\n",
      "      - problem\t0.013\n",
      "      - probability\t0.011\n",
      "      - exam\t0.010\n",
      "   Topic #7\n",
      "      - energy\t0.022\n",
      "      - circuit\t0.017\n",
      "      - sensor\t0.013\n",
      "      - power\t0.012\n",
      "      - device\t0.009\n",
      "   Topic #8\n",
      "      - flow\t0.015\n",
      "      - application\t0.014\n",
      "      - cell\t0.012\n",
      "      - mass\t0.011\n",
      "      - heat\t0.011\n",
      "   Topic #9\n",
      "      - process\t0.018\n",
      "      - chemistry\t0.016\n",
      "      - control\t0.012\n",
      "      - water\t0.009\n",
      "      - reactor\t0.008\n",
      "   Topic #10\n",
      "      - group\t0.014\n",
      "      - work\t0.010\n",
      "      - presentation\t0.009\n",
      "      - engineering\t0.008\n",
      "      - activity\t0.007\n",
      "For alpha = 50.00\n",
      "   Topic #1\n",
      "      - application\t0.005\n",
      "      - problem\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - material\t0.005\n",
      "   Topic #2\n",
      "      - work\t0.005\n",
      "      - skill\t0.005\n",
      "      - keywords\t0.005\n",
      "      - material\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #3\n",
      "      - problem\t0.005\n",
      "      - material\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #4\n",
      "      - skill\t0.005\n",
      "      - keywords\t0.005\n",
      "      - work\t0.005\n",
      "      - problem\t0.005\n",
      "      - process\t0.005\n",
      "   Topic #5\n",
      "      - skill\t0.005\n",
      "      - report\t0.005\n",
      "      - work\t0.005\n",
      "      - problem\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #6\n",
      "      - theory\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - introduction\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #7\n",
      "      - material\t0.005\n",
      "      - application\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - work\t0.005\n",
      "   Topic #8\n",
      "      - architecture\t0.005\n",
      "      - application\t0.005\n",
      "      - material\t0.005\n",
      "      - keywords\t0.005\n",
      "      - introduction\t0.004\n",
      "   Topic #9\n",
      "      - problem\t0.005\n",
      "      - skill\t0.005\n",
      "      - keywords\t0.005\n",
      "      - process\t0.005\n",
      "      - work\t0.005\n",
      "   Topic #10\n",
      "      - keywords\t0.005\n",
      "      - problem\t0.005\n",
      "      - skill\t0.005\n",
      "      - activity\t0.005\n",
      "      - work\t0.005\n"
     ]
    }
   ],
   "source": [
    "for alpha in [1.01,5.0,50.0]:\n",
    "    print('For alpha = %.2f'%alpha)\n",
    "    model2 = LDA.train(courses,k=10,docConcentration=alpha,topicConcentration=1.01,seed=1)\n",
    "    for idx, topics in enumerate(model2.describeTopics(5)):\n",
    "        print('   Topic #%d'%(idx+1))\n",
    "        for termIdx, term in enumerate(topics[0]):\n",
    "            print('      - %s\\t%.3f'%(idx2Term[term],topics[1][termIdx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a big value of alpha, we should have a uniform distribution of topics over documents. It means that all documents are very similar.\n",
    "\n",
    "It becomes hard to extract relevant topics of such a set as each topic will have the same distribution of words, because we try to analyse the topics over similars documents. The words per topics will simply be the most popular words over the whole documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For beta = 1.01\n",
      "   Topic #1\n",
      "      - algorithm\t0.018\n",
      "      - programming\t0.014\n",
      "      - problem\t0.012\n",
      "      - structure\t0.012\n",
      "      - communication\t0.011\n",
      "   Topic #2\n",
      "      - optical\t0.014\n",
      "      - optic\t0.014\n",
      "      - image\t0.014\n",
      "      - material\t0.013\n",
      "      - microscopy\t0.012\n",
      "   Topic #3\n",
      "      - chemical\t0.017\n",
      "      - biology\t0.015\n",
      "      - molecular\t0.015\n",
      "      - protein\t0.012\n",
      "      - reaction\t0.011\n",
      "   Topic #4\n",
      "      - modeling\t0.013\n",
      "      - research\t0.010\n",
      "      - information\t0.008\n",
      "      - presentation\t0.008\n",
      "      - tool\t0.008\n",
      "   Topic #5\n",
      "      - report\t0.029\n",
      "      - skill\t0.019\n",
      "      - plan\t0.017\n",
      "      - scientific\t0.017\n",
      "      - research\t0.014\n",
      "   Topic #6\n",
      "      - theory\t0.019\n",
      "      - linear\t0.019\n",
      "      - problem\t0.013\n",
      "      - probability\t0.011\n",
      "      - exam\t0.011\n",
      "   Topic #7\n",
      "      - energy\t0.021\n",
      "      - circuit\t0.017\n",
      "      - sensor\t0.013\n",
      "      - power\t0.012\n",
      "      - technology\t0.009\n",
      "   Topic #8\n",
      "      - flow\t0.015\n",
      "      - application\t0.014\n",
      "      - cell\t0.013\n",
      "      - mass\t0.011\n",
      "      - heat\t0.010\n",
      "   Topic #9\n",
      "      - process\t0.018\n",
      "      - chemistry\t0.016\n",
      "      - control\t0.012\n",
      "      - water\t0.009\n",
      "      - reactor\t0.008\n",
      "   Topic #10\n",
      "      - group\t0.013\n",
      "      - work\t0.010\n",
      "      - presentation\t0.009\n",
      "      - activity\t0.008\n",
      "      - engineering\t0.007\n",
      "For beta = 2.50\n",
      "   Topic #1\n",
      "      - material\t0.006\n",
      "      - problem\t0.006\n",
      "      - theory\t0.006\n",
      "      - algorithm\t0.005\n",
      "      - technique\t0.005\n",
      "   Topic #2\n",
      "      - optic\t0.012\n",
      "      - optical\t0.011\n",
      "      - microscopy\t0.009\n",
      "      - imaging\t0.008\n",
      "      - material\t0.007\n",
      "   Topic #3\n",
      "      - chemical\t0.009\n",
      "      - reaction\t0.008\n",
      "      - engineering\t0.006\n",
      "      - process\t0.006\n",
      "      - chemistry\t0.005\n",
      "   Topic #4\n",
      "      - plan\t0.006\n",
      "      - skill\t0.006\n",
      "      - work\t0.006\n",
      "      - presentation\t0.006\n",
      "      - research\t0.005\n",
      "   Topic #5\n",
      "      - report\t0.013\n",
      "      - risk\t0.010\n",
      "      - skill\t0.008\n",
      "      - plan\t0.007\n",
      "      - research\t0.007\n",
      "   Topic #6\n",
      "      - linear\t0.012\n",
      "      - theory\t0.012\n",
      "      - probability\t0.010\n",
      "      - stochastic\t0.008\n",
      "      - problem\t0.008\n",
      "   Topic #7\n",
      "      - energy\t0.016\n",
      "      - material\t0.006\n",
      "      - application\t0.006\n",
      "      - circuit\t0.005\n",
      "      - control\t0.005\n",
      "   Topic #8\n",
      "      - cell\t0.016\n",
      "      - laser\t0.011\n",
      "      - material\t0.010\n",
      "      - application\t0.009\n",
      "      - principle\t0.008\n",
      "   Topic #9\n",
      "      - process\t0.006\n",
      "      - skill\t0.006\n",
      "      - control\t0.006\n",
      "      - work\t0.006\n",
      "      - presentation\t0.005\n",
      "   Topic #10\n",
      "      - presentation\t0.006\n",
      "      - work\t0.006\n",
      "      - research\t0.006\n",
      "      - skill\t0.005\n",
      "      - report\t0.005\n",
      "For beta = 10.00\n",
      "   Topic #1\n",
      "      - keywords\t0.005\n",
      "      - problem\t0.005\n",
      "      - material\t0.005\n",
      "      - skill\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #2\n",
      "      - skill\t0.005\n",
      "      - keywords\t0.005\n",
      "      - work\t0.005\n",
      "      - material\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #3\n",
      "      - problem\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - work\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #4\n",
      "      - keywords\t0.004\n",
      "      - skill\t0.004\n",
      "      - application\t0.004\n",
      "      - problem\t0.004\n",
      "      - work\t0.004\n",
      "   Topic #5\n",
      "      - skill\t0.005\n",
      "      - work\t0.005\n",
      "      - problem\t0.005\n",
      "      - keywords\t0.005\n",
      "      - material\t0.005\n",
      "   Topic #6\n",
      "      - keywords\t0.005\n",
      "      - application\t0.005\n",
      "      - problem\t0.005\n",
      "      - skill\t0.005\n",
      "      - material\t0.005\n",
      "   Topic #7\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - application\t0.005\n",
      "      - material\t0.005\n",
      "      - work\t0.005\n",
      "   Topic #8\n",
      "      - application\t0.005\n",
      "      - material\t0.005\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.005\n",
      "      - work\t0.005\n",
      "   Topic #9\n",
      "      - skill\t0.005\n",
      "      - problem\t0.005\n",
      "      - keywords\t0.005\n",
      "      - work\t0.005\n",
      "      - application\t0.005\n",
      "   Topic #10\n",
      "      - keywords\t0.005\n",
      "      - skill\t0.004\n",
      "      - problem\t0.004\n",
      "      - application\t0.004\n",
      "      - work\t0.004\n"
     ]
    }
   ],
   "source": [
    "for beta in [1.01,2.5,10.0]:\n",
    "    print('For beta = %.2f'%beta)\n",
    "    model2 = LDA.train(courses,k=10,docConcentration=6.0,topicConcentration=beta,seed=1)\n",
    "    for idx, topics in enumerate(model2.describeTopics(5)):\n",
    "        print('   Topic #%d'%(idx+1))\n",
    "        for termIdx, term in enumerate(topics[0]):\n",
    "            print('      - %s\\t%.3f'%(idx2Term[term],topics[1][termIdx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "With a big value of beta, we can see that, as expected, the term-distribution of each topic is very likely to be uniform, so the topics are all similar.\n",
    "\n",
    "With a smaller value, the distribution is more sparse and random, but it quickly increase to a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "   - molecular\t0.024\n",
      "   - protein\t0.017\n",
      "   - biology\t0.017\n",
      "   - paper\t0.016\n",
      "   - reaction\t0.016\n",
      "Topic #2\n",
      "   - programming\t0.017\n",
      "   - digital\t0.015\n",
      "   - language\t0.012\n",
      "   - modeling\t0.010\n",
      "   - signal\t0.010\n",
      "Topic #3\n",
      "   - control\t0.039\n",
      "   - stability\t0.012\n",
      "   - circuit\t0.009\n",
      "   - work\t0.009\n",
      "   - session\t0.008\n",
      "Topic #4\n",
      "   - brain\t0.011\n",
      "   - scientific\t0.009\n",
      "   - field\t0.009\n",
      "   - neuroscience\t0.008\n",
      "   - architecture\t0.008\n",
      "Topic #5\n",
      "   - cell\t0.015\n",
      "   - structure\t0.012\n",
      "   - week\t0.012\n",
      "   - electrochemical\t0.011\n",
      "   - problem\t0.010\n",
      "Topic #6\n",
      "   - skill\t0.013\n",
      "   - plan\t0.012\n",
      "   - presentation\t0.012\n",
      "   - class\t0.011\n",
      "   - evaluate\t0.011\n",
      "Topic #7\n",
      "   - technology\t0.021\n",
      "   - policy\t0.019\n",
      "   - communication\t0.010\n",
      "   - development\t0.009\n",
      "   - engineering\t0.008\n",
      "Topic #8\n",
      "   - optic\t0.024\n",
      "   - image\t0.022\n",
      "   - imaging\t0.022\n",
      "   - optical\t0.015\n",
      "   - microscopy\t0.012\n",
      "Topic #9\n",
      "   - risk\t0.020\n",
      "   - report\t0.015\n",
      "   - skill\t0.012\n",
      "   - plan\t0.011\n",
      "   - information\t0.010\n",
      "Topic #10\n",
      "   - device\t0.025\n",
      "   - material\t0.024\n",
      "   - application\t0.018\n",
      "   - property\t0.017\n",
      "   - mechanical\t0.011\n",
      "Topic #11\n",
      "   - laser\t0.024\n",
      "   - theory\t0.014\n",
      "   - probability\t0.011\n",
      "   - stochastic\t0.010\n",
      "   - network\t0.009\n",
      "Topic #12\n",
      "   - report\t0.014\n",
      "   - work\t0.012\n",
      "   - semester\t0.012\n",
      "   - plan\t0.010\n",
      "   - structure\t0.008\n",
      "Topic #13\n",
      "   - problem\t0.025\n",
      "   - linear\t0.021\n",
      "   - equation\t0.019\n",
      "   - algorithm\t0.016\n",
      "   - theory\t0.016\n",
      "Topic #14\n",
      "   - magnetic\t0.022\n",
      "   - information\t0.012\n",
      "   - material\t0.011\n",
      "   - acoustic\t0.011\n",
      "   - simulation\t0.009\n",
      "Topic #15\n",
      "   - flow\t0.019\n",
      "   - material\t0.016\n",
      "   - communication\t0.014\n",
      "   - property\t0.010\n",
      "   - speech\t0.010\n",
      "Topic #16\n",
      "   - power\t0.011\n",
      "   - application\t0.011\n",
      "   - circuit\t0.009\n",
      "   - product\t0.009\n",
      "   - converter\t0.008\n",
      "Topic #17\n",
      "   - chemistry\t0.025\n",
      "   - chemical\t0.023\n",
      "   - organic\t0.020\n",
      "   - reaction\t0.015\n",
      "   - polymer\t0.013\n",
      "Topic #18\n",
      "   - engineering\t0.022\n",
      "   - mass\t0.011\n",
      "   - cancer\t0.010\n",
      "   - research\t0.009\n",
      "   - module\t0.009\n",
      "Topic #19\n",
      "   - energy\t0.047\n",
      "   - process\t0.026\n",
      "   - water\t0.013\n",
      "   - conversion\t0.012\n",
      "   - environmental\t0.011\n",
      "Topic #20\n",
      "   - sensor\t0.017\n",
      "   - note\t0.013\n",
      "   - signal\t0.011\n",
      "   - measurement\t0.011\n",
      "   - technique\t0.010\n"
     ]
    }
   ],
   "source": [
    "model = LDA.train(courses,k=20,docConcentration=1.0001,topicConcentration=3.0,seed=1)\n",
    "for idx, topics in enumerate(model.describeTopics(5)):\n",
    "    print('Topic #%d'%(idx+1))\n",
    "    for termIdx, term in enumerate(topics[0]):\n",
    "        print('   - %s\\t%.3f'%(idx2Term[term],topics[1][termIdx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "- $k$ = 20, since there is a lot of subjects being thaught at EPFL\n",
    "- $\\alpha = 1.0001$, smallest value possible, since a course rarely teaches more than on topic\n",
    "- $\\beta = 3.0$, we wanted the word per document to be quite uniform, but not too much in since a lot of terms repeat from one course to another since they are often linked\n",
    "\n",
    "## 3.\n",
    "1. Biology\n",
    "2. IC\n",
    "3. Micro-engineering\n",
    "4. Neurosciences\n",
    "5. Cells\n",
    "6. Professional skills\n",
    "7. Role of engineer\n",
    "8. Imagery\n",
    "9. Statistics\n",
    "10. Hardware\n",
    "11. Fiber networks\n",
    "12. Projects\n",
    "13. Mathematics\n",
    "14. Physics\n",
    "15. Sound\n",
    "16. Electricity\n",
    "17. Chemistry\n",
    "18. Medical engineering\n",
    "19. Ecology\n",
    "20. Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/ix/wikipedia-for-schools.txt\").map(json.loads)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the data has already been mostly preprocessed, we only remove all words which have length smaller than 2, remove numbers and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We filter the words, make a distinct list with all words and indices.\n",
    "vocabulary = data \\\n",
    "    .map(lambda page: [word.lower() for word in page['tokens'] if (word.isalpha() and len(word) > 2 and word.lower() not in stopwords)]) \\\n",
    "    .flatMap(lambda x: x) \\\n",
    "    .distinct() \\\n",
    "    .zipWithIndex() \\\n",
    "    .collectAsMap()\n",
    "    \n",
    "id2voc = {v: k for k,v in vocabulary.items()}\n",
    "\n",
    "# We construct the vectors by giving them as indices the page id\n",
    "# Then we make the count of each term in the page\n",
    "def page_vector(page):\n",
    "    id = page['page_id']-1\n",
    "    counts = defaultdict(int)\n",
    "    for token in page['tokens']:\n",
    "        if token in vocabulary:\n",
    "            counts[vocabulary[token]] += 1\n",
    "    counts = sorted(counts.items())\n",
    "    keys = [x[0] for x in counts]\n",
    "    values = [x[1] for x in counts]\n",
    "    return (id, Vectors.sparse(len(vocabulary), keys, values))\n",
    "pages = data.map(page_vector).map(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the value of $\\alpha$, what makes most sense is to have a small value, since there should rarely be more than one or two topics per wikipedia page, thus we chose $\\alpha = 0.1$\n",
    "\n",
    "For the value of $\\beta$, we felt that the word term distribution per topic should be quite uniform, since wikipedia covers of wide range of subjet on the topics, we chose $\\beta = 2.0$\n",
    "\n",
    "For $k$, we wanted the value to be quite big, however, the cluster was not able to run LDA with a value bigger than 10. It would have made more sense to choose a $k = 50$ or even more (since we have more than 5000 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "  - water\t0.000128\n",
      "  - acid\t0.000110\n",
      "  - coupler\t0.000107\n",
      "  - love\t0.000082\n",
      "  - system\t0.000080\n",
      "Topic #2\n",
      "  - tolkien\t0.000067\n",
      "  - bush\t0.000059\n",
      "  - war\t0.000057\n",
      "  - states\t0.000051\n",
      "  - united\t0.000051\n",
      "Topic #3\n",
      "  - ilex\t0.000173\n",
      "  - bass\t0.000145\n",
      "  - galaxy\t0.000113\n",
      "  - cormorant\t0.000112\n",
      "  - phalacrocorax\t0.000111\n",
      "Topic #4\n",
      "  - time\t0.002039\n",
      "  - years\t0.001808\n",
      "  - world\t0.001788\n",
      "  - american\t0.001661\n",
      "  - war\t0.001625\n",
      "Topic #5\n",
      "  - hippos\t0.000108\n",
      "  - hippopotamus\t0.000085\n",
      "  - water\t0.000054\n",
      "  - nematodes\t0.000047\n",
      "  - chinese\t0.000041\n",
      "Topic #6\n",
      "  - pluto\t0.000156\n",
      "  - set\t0.000126\n",
      "  - theory\t0.000110\n",
      "  - time\t0.000085\n",
      "  - string\t0.000079\n",
      "Topic #7\n",
      "  - american\t0.000064\n",
      "  - states\t0.000061\n",
      "  - united\t0.000058\n",
      "  - hamilton\t0.000056\n",
      "  - war\t0.000047\n",
      "Topic #8\n",
      "  - tubman\t0.000143\n",
      "  - theatre\t0.000109\n",
      "  - city\t0.000100\n",
      "  - house\t0.000081\n",
      "  - hänsel\t0.000081\n",
      "Topic #9\n",
      "  - shinto\t0.000190\n",
      "  - god\t0.000140\n",
      "  - sheep\t0.000096\n",
      "  - theory\t0.000087\n",
      "  - kami\t0.000087\n",
      "Topic #10\n",
      "  - acid\t0.000082\n",
      "  - scattered\t0.000063\n",
      "  - war\t0.000059\n",
      "  - acids\t0.000052\n",
      "  - king\t0.000052\n"
     ]
    }
   ],
   "source": [
    "modelWiki = LDA.train(pages,k=10,docConcentration=0.1,topicConcentration=2.0,seed=1,optimizer='online')\n",
    "\n",
    "for idx, topics in enumerate(modelWiki.describeTopics(5)):\n",
    "    if(idx > 10):\n",
    "        break\n",
    "    print('Topic #%d'%(idx+1))\n",
    "    for termIdx, term in enumerate(topics[0]):\n",
    "        print('  - %s\\t%f'%(id2voc[term],topics[1][termIdx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not really conviced by the results, the number of topic is certainly way too small...\n",
    "\n",
    "Attempt of giving labels:\n",
    "1. ?\n",
    "2. ?\n",
    "3. ?\n",
    "4. World war\n",
    "5. Hippopotamus\n",
    "6. Planet theory ?\n",
    "7. American Revolutionary War\n",
    "8. ?\n",
    "9. Religion\n",
    "10. ?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
