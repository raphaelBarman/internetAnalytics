{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** R\n",
    "**Names:**\n",
    "\n",
    "* Raphael Strebel\n",
    "* Raphaël Barman\n",
    "* Thierry Bossy\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "import string\n",
    "import re\n",
    "import operator\n",
    "import nltk\n",
    "import math\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Add a word to the bag of word given as parameter\n",
    "def add2bow(word, bow):\n",
    "    #newbow = bow.copy()\n",
    "    if word not in bow:\n",
    "        bow[word] = 0\n",
    "    bow[word] += 1\n",
    "    return bow\n",
    "\n",
    "# Merges to bag of words\n",
    "def mergeBow(bow1, bow2):\n",
    "    #newbow = bow1.copy()\n",
    "    for word, occ in bow2.items():\n",
    "        if word not in bow1:\n",
    "            bow1[word] = 0\n",
    "        bow1[word] += occ\n",
    "    return bow1\n",
    "\n",
    "# Returns the bag of words of a text as a dictionary, so the different words as keys and their number of occurence as value\n",
    "def getBagOfWords(text):\n",
    "    bow = {}\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    text = text.split(' ')\n",
    "    for idx in range(len(text)):\n",
    "        word = text[idx]\n",
    "        # separate words such that \"MyNameIsChristian\" becomes \"My\" \"Name\" \"Is\" \"Christian\"\n",
    "        res = re.findall('[a-zA-Z][^A-Z]*',word)\n",
    "        if res:\n",
    "            if len(min(res,key=len)) != 1:\n",
    "                if len(res) > 0:\n",
    "                    text[idx] = ''\n",
    "                for match in res:\n",
    "                    text.append(match)\n",
    "    text = [x for x in text if x != '']\n",
    "    for idx in range(len(text)):\n",
    "        word = text[idx]\n",
    "        # Keep words that are only upper case as such (we don't want IT to become it) and put all others as lower case\n",
    "        if not word.isupper():\n",
    "            word = word.lower()\n",
    "        # Lemmatize all non-digit words \n",
    "        if not word.isdigit() and not word in stopwords:\n",
    "            bow = add2bow(lmtzr.lemmatize(word),bow)\n",
    "            #add2bow(stemmer.stem(word),bow)\n",
    "#     for word in textCopy:\n",
    "#         if not word.isupper():\n",
    "#             word = word.lower()\n",
    "#         if not word.isdigit():\n",
    "#             text.add(lmtzr.lemmatize(word))\n",
    "#     for word in stopwords:\n",
    "#         try:\n",
    "#             text.remove(word)\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "    return bow\n",
    "\n",
    "\n",
    "# Compute bag of words for the description of every course, then merge them and return the global bag of words\n",
    "def getGlobalBagOfWords(ourCourses):\n",
    "    globalBagOfWords = {}\n",
    "    bagOfWords = {}\n",
    "    for course in ourCourses:\n",
    "        #localBow = {}\n",
    "        localBow = getBagOfWords(course['description'])\n",
    "        bagOfWords[course['courseId']] = localBow\n",
    "        localBow = mergeBow(globalBagOfWords,localBow)\n",
    "    return globalBagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428382\n"
     ]
    }
   ],
   "source": [
    "globalBagOfWords = {}\n",
    "globalBagOfWords = getGlobalBagOfWords(courses)\n",
    "print(sum(globalBagOfWords.values()))\n",
    "#getBagOfWords(courses[1]['description'])\n",
    "#for course in courses:\n",
    "#    bow = getBagOfWords(course['description'])\n",
    "#    bagOfWords[course['courseId']] = bow\n",
    "#    mergeBow(globalBagOfWord,bow)\n",
    "#test_course = course.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to remove all punctuation and all stopwords since there really is no interest in keeping them.\n",
    "We also lemmatize the words using the nltk library, to keep track of similar words and have a more accurate word occurence count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Image Processing for Life Science', 'description': 'This course intends to teach image processing with a strong emphasis of applications in life sciences. The idea is to enable the participants to solve image processing questions via workflows independently. Content Over the last decades, the images arising from microscopes in Life Sciences went from being a qualitative support of scientific evidence to a quantitative resource. To obtain good quality data from digital images, be it from a photograph of a Western blot, a TEM slice or a multi-channel confocal time-lapse stack, scientists must understand the underlying processes leading to the extracted information. Of similar importance is the software used to obtain the data. This course makes use of the ImageJ (FIJI package) as well as other open-source tools to ensure maximum reproducibility and protocol transfer of the analysis pipelines. The course will span 14 weeks with 1h30 of lecture per week, as well as exercises to complete outside of the course and will enable to students to establish image analysis workflows autonomously. Note This course is open to max. 16 students selected by the organizer. This 14-week course aims to introduce students to digital image analysis in the context of life sciences. We will cover the following topics:- Digital image data representations, formats, metadata- Image manipulation- Macro and script creation- Filtering, linear, non-linear, morphological- Segmentation- Regions of interest- Image stitching- Image visualisation- Data extraction and representation- Image deconvolution and denoising- Machine learning Each topic will have a strong emphasis on good practices and will be followed by exercises to be handed out at the next session. Exercises will involve the creation of macros or scripts to reach a defined goal. The exercises are to be completed as autonomous homework, outside of lecture hours. Keywords Biology, Image Processing, Microscopy, ImageJ, FIJI, Macros, Data, Segmentation,Filtering Visualisation Open so Assessment methods Continuous Multiple', 'courseId': 'BIO-695'}\n",
      "{'arising': 1, 'exercise': 4, 'learning': 1, 'organizer': 1, 'pipeline': 1, 'session': 1, 'independently': 1, 'creation': 2, 'continuous': 1, 'morphological': 1, 'processing': 3, 'complete': 1, 'completed': 1, 'denoising': 1, 'leading': 1, 'content': 1, 'evidence': 1, 'question': 1, 'visualisation': 2, 'scientific': 1, 'package': 1, 'emphasis': 2, 'script': 2, 'tool': 1, 'application': 1, 'scientist': 1, 'extracted': 1, 'involve': 1, 'protocol': 1, 'establish': 1, 'student': 3, 'qualitative': 1, 'microscope': 1, 'week': 3, 'teach': 1, 'segmentation': 2, 'strong': 2, 'keywords': 1, 'assessment': 1, 'metadata': 1, 'FIJI': 2, 'timelapse': 1, 'workflow': 2, 'manipulation': 1, 'solve': 1, 'decade': 1, 'stack': 1, 'representation': 2, 'process': 1, 'importance': 1, 'science': 3, 'handed': 1, 'method': 1, 'opensource': 1, 'context': 1, 'understand': 1, 'reproducibility': 1, 'autonomous': 1, 'slice': 1, 'region': 1, 'interest': 1, 'intends': 1, 'filtering': 2, 'open': 2, 'blot': 1, 'h30': 1, 'multichannel': 1, 'obtain': 2, 'TEM': 1, 'format': 1, 'biology': 1, 'life': 3, 'linear': 1, 'defined': 1, 'confocal': 1, 'selected': 1, 'reach': 1, 'photograph': 1, 'information': 1, 'extraction': 1, 'stitching': 1, 'make': 1, 'resource': 1, 'note': 1, 'data': 5, 'multiple': 1, 'software': 1, 'support': 1, 'machine': 1, 'span': 1, 'practice': 1, 'autonomously': 1, 'introduce': 1, 'similar': 1, 'goal': 1, 'nonlinear': 1, 'lecture': 2, 'topic': 2, 'good': 2, 'aim': 1, 'western': 1, 'idea': 1, 'deconvolution': 1, 'image': 12, 'hour': 1, 'quantitative': 1, 'macro': 3, 'maximum': 1, 'participant': 1, 'ensure': 1, 'underlying': 1, 'cover': 1, 'homework': 1, 'enable': 2, 'imagej': 2, 'analysis': 3, 'quality': 1, 'digital': 3, 'microscopy': 1, 'transfer': 1, 'max': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BIO-695': {'FIJI': 2,\n",
       "  'TEM': 1,\n",
       "  'aim': 1,\n",
       "  'analysis': 3,\n",
       "  'application': 1,\n",
       "  'arising': 1,\n",
       "  'assessment': 1,\n",
       "  'autonomous': 1,\n",
       "  'autonomously': 1,\n",
       "  'biology': 1,\n",
       "  'blot': 1,\n",
       "  'complete': 1,\n",
       "  'completed': 1,\n",
       "  'confocal': 1,\n",
       "  'content': 1,\n",
       "  'context': 1,\n",
       "  'continuous': 1,\n",
       "  'cover': 1,\n",
       "  'creation': 2,\n",
       "  'data': 5,\n",
       "  'decade': 1,\n",
       "  'deconvolution': 1,\n",
       "  'defined': 1,\n",
       "  'denoising': 1,\n",
       "  'digital': 3,\n",
       "  'emphasis': 2,\n",
       "  'enable': 2,\n",
       "  'ensure': 1,\n",
       "  'establish': 1,\n",
       "  'evidence': 1,\n",
       "  'exercise': 4,\n",
       "  'extracted': 1,\n",
       "  'extraction': 1,\n",
       "  'filtering': 2,\n",
       "  'format': 1,\n",
       "  'goal': 1,\n",
       "  'good': 2,\n",
       "  'h30': 1,\n",
       "  'handed': 1,\n",
       "  'homework': 1,\n",
       "  'hour': 1,\n",
       "  'idea': 1,\n",
       "  'image': 12,\n",
       "  'imagej': 2,\n",
       "  'importance': 1,\n",
       "  'independently': 1,\n",
       "  'information': 1,\n",
       "  'intends': 1,\n",
       "  'interest': 1,\n",
       "  'introduce': 1,\n",
       "  'involve': 1,\n",
       "  'keywords': 1,\n",
       "  'leading': 1,\n",
       "  'learning': 1,\n",
       "  'lecture': 2,\n",
       "  'life': 3,\n",
       "  'linear': 1,\n",
       "  'machine': 1,\n",
       "  'macro': 3,\n",
       "  'make': 1,\n",
       "  'manipulation': 1,\n",
       "  'max': 1,\n",
       "  'maximum': 1,\n",
       "  'metadata': 1,\n",
       "  'method': 1,\n",
       "  'microscope': 1,\n",
       "  'microscopy': 1,\n",
       "  'morphological': 1,\n",
       "  'multichannel': 1,\n",
       "  'multiple': 1,\n",
       "  'nonlinear': 1,\n",
       "  'note': 1,\n",
       "  'obtain': 2,\n",
       "  'open': 2,\n",
       "  'opensource': 1,\n",
       "  'organizer': 1,\n",
       "  'package': 1,\n",
       "  'participant': 1,\n",
       "  'photograph': 1,\n",
       "  'pipeline': 1,\n",
       "  'practice': 1,\n",
       "  'process': 1,\n",
       "  'processing': 3,\n",
       "  'protocol': 1,\n",
       "  'qualitative': 1,\n",
       "  'quality': 1,\n",
       "  'quantitative': 1,\n",
       "  'question': 1,\n",
       "  'reach': 1,\n",
       "  'region': 1,\n",
       "  'representation': 2,\n",
       "  'reproducibility': 1,\n",
       "  'resource': 1,\n",
       "  'science': 3,\n",
       "  'scientific': 1,\n",
       "  'scientist': 1,\n",
       "  'script': 2,\n",
       "  'segmentation': 2,\n",
       "  'selected': 1,\n",
       "  'session': 1,\n",
       "  'similar': 1,\n",
       "  'slice': 1,\n",
       "  'software': 1,\n",
       "  'solve': 1,\n",
       "  'span': 1,\n",
       "  'stack': 1,\n",
       "  'stitching': 1,\n",
       "  'strong': 2,\n",
       "  'student': 3,\n",
       "  'support': 1,\n",
       "  'teach': 1,\n",
       "  'timelapse': 1,\n",
       "  'tool': 1,\n",
       "  'topic': 2,\n",
       "  'transfer': 1,\n",
       "  'underlying': 1,\n",
       "  'understand': 1,\n",
       "  'visualisation': 2,\n",
       "  'week': 3,\n",
       "  'western': 1,\n",
       "  'workflow': 2}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_course = courses[1]\n",
    "bagOfWords = {}\n",
    "#globalBagOfWord = {}\n",
    "#getBagOfWords(courses[1]['description'])\n",
    "print(test_course)\n",
    "bow = getBagOfWords(test_course['description'])\n",
    "bagOfWords[test_course['courseId']] = bow\n",
    "#mergeBow(globalBagOfWord,bow)\n",
    "print(bow)\n",
    "dict(sorted(bagOfWords.items(), key=operator.itemgetter(1), reverse=True)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interconnect': 3,\n",
       " 'postprimary': 3,\n",
       " 'inaction': 3,\n",
       " 'others6': 3,\n",
       " 'mechanosensory': 3,\n",
       " 'hyperelliptic': 3,\n",
       " 'FDD': 3,\n",
       " 'WINGS': 3,\n",
       " 'FRP': 3,\n",
       " 'valentine': 3,\n",
       " 'curable': 3,\n",
       " 'epifourier': 3,\n",
       " 'applications10': 3,\n",
       " 'emblematic': 3,\n",
       " 'microdispersed': 3,\n",
       " 'propagator': 3,\n",
       " 'photopolymers': 3,\n",
       " 'equivallent': 3,\n",
       " 'adaption': 3,\n",
       " 'aidistributed': 3,\n",
       " 'techniquesformulate': 3,\n",
       " 'gyromagnetic': 3,\n",
       " 'perl': 3,\n",
       " 'brief': 3,\n",
       " 'refreshment': 3,\n",
       " 'poroelasticity': 3,\n",
       " 'metaloxide': 3,\n",
       " 'ah20identify': 3,\n",
       " 'kirchoffs': 3,\n",
       " 'lawson': 3,\n",
       " 'EE332': 3,\n",
       " 'BBC': 3,\n",
       " 'skundin': 3,\n",
       " 'oksana': 3,\n",
       " 'decorrelation': 3,\n",
       " 'FINAL': 3,\n",
       " 'NEM': 3,\n",
       " 'transcriptase': 3,\n",
       " '2B': 3,\n",
       " 'processmicrostructure': 3,\n",
       " 'pip3signaling': 3,\n",
       " 'sectoral': 3,\n",
       " 'nozzle': 3,\n",
       " 'vestibular': 3,\n",
       " 'EPMAWDX': 3,\n",
       " 'light42': 3,\n",
       " 'dijkstras': 3,\n",
       " 'T3': 3,\n",
       " 'spontenaous': 3,\n",
       " 'URL': 3,\n",
       " 'multitemporal': 3,\n",
       " 'principles3': 3,\n",
       " 'hamming': 3,\n",
       " 'httpvectorcom': 3,\n",
       " 'orthopaedic': 3,\n",
       " 'subunit': 3,\n",
       " 'materialsapplications': 3,\n",
       " 'firouzeh': 3,\n",
       " 'vivian': 3,\n",
       " 'yearend': 3,\n",
       " 'incrementaliterative': 3,\n",
       " 'labexercise': 3,\n",
       " 'absorber': 3,\n",
       " 'thickeningstabilisationdewatering': 3,\n",
       " 'gmmbased': 3,\n",
       " 'reception': 3,\n",
       " 'diagrammes': 3,\n",
       " 'facilitates': 3,\n",
       " 'electrolysis': 3,\n",
       " 'DOF': 3,\n",
       " 'VQ': 3,\n",
       " 'misfolding': 3,\n",
       " 'twodimensionnal': 3,\n",
       " 'widespread': 3,\n",
       " 'CLI': 3,\n",
       " 'interactions2': 3,\n",
       " 'intensification': 3,\n",
       " 'gamal': 3,\n",
       " 'synchrone': 3,\n",
       " 'qualtiy': 3,\n",
       " 'electronical': 3,\n",
       " 'pharmabiomedical': 3,\n",
       " 'droop': 3,\n",
       " 'stœchiometry': 3,\n",
       " 'potable': 3,\n",
       " 'extemporaneous': 3,\n",
       " 'biology4': 3,\n",
       " 'incompatibility': 3,\n",
       " 'LTE': 3,\n",
       " 'internalized': 3,\n",
       " 'nonnormal': 3,\n",
       " 'draining': 3,\n",
       " 'leak': 3,\n",
       " 'owing': 3,\n",
       " 'huron': 3,\n",
       " 'palmer': 3,\n",
       " 'originality': 3,\n",
       " 'EBIC': 3,\n",
       " 'williams': 3,\n",
       " 'TCM': 3,\n",
       " 'missionoriented': 3,\n",
       " 'krane': 3,\n",
       " 'pressurized': 3,\n",
       " 'triggered': 3,\n",
       " 'fretbased': 3,\n",
       " 'dissolved': 3,\n",
       " 'proposal25': 3,\n",
       " 'serveral': 3,\n",
       " 'dcampepflch': 3,\n",
       " 'progesterone': 3,\n",
       " 'smoothness': 3,\n",
       " 'DRAM': 3,\n",
       " '443b': 3,\n",
       " 'aroma': 3,\n",
       " 'spoken': 3,\n",
       " 'developping': 3,\n",
       " 'spirale': 3,\n",
       " 'questionandanswer': 3,\n",
       " 'crosscoupled': 3,\n",
       " 'gas4': 3,\n",
       " 'caractères': 3,\n",
       " 'trained': 3,\n",
       " 'technologies2': 3,\n",
       " 'relaxation8': 3,\n",
       " 'ABCD': 3,\n",
       " 'diods': 3,\n",
       " 'thegrading': 3,\n",
       " 'stability6': 3,\n",
       " 'langrangian': 3,\n",
       " 'inbetween': 3,\n",
       " 'transformative': 3,\n",
       " 'noncircular': 3,\n",
       " 'recommeded': 3,\n",
       " 'microscopist': 3,\n",
       " 'abroad': 3,\n",
       " 'transitions32': 3,\n",
       " 'internationally': 3,\n",
       " 'sessin': 3,\n",
       " 'strategies55': 3,\n",
       " 'coupledoscillators': 3,\n",
       " 'resourceefficient': 3,\n",
       " 'indicative': 3,\n",
       " 'ragone': 3,\n",
       " 'opacity': 3,\n",
       " 'faded': 3,\n",
       " 'analyzeand': 3,\n",
       " 'filgueiras': 3,\n",
       " 'microarchitectures': 3,\n",
       " 'imagessimulate': 3,\n",
       " 'andmagnetization': 3,\n",
       " 'kim': 3,\n",
       " 'originating': 3,\n",
       " 'tridiagonal': 3,\n",
       " 'appoaches': 3,\n",
       " 'normed': 3,\n",
       " 'epistemetechne': 3,\n",
       " 'SURFACE': 3,\n",
       " 'triggering': 3,\n",
       " 'nonchemosensory': 3,\n",
       " 'buckingham': 3,\n",
       " 'tamas': 3,\n",
       " 'offboardonboard': 3,\n",
       " 'enviroment': 3,\n",
       " 'develope': 3,\n",
       " 'pressurised': 3,\n",
       " 'intention': 3,\n",
       " 'freelyjointed': 3,\n",
       " 'hyphenation': 3,\n",
       " 'specialworkshops': 3,\n",
       " 'ETH': 3,\n",
       " 'measurementcharacterization': 3,\n",
       " 'E8': 3,\n",
       " 'wesolowski': 3,\n",
       " 'alteration': 3,\n",
       " 'solvable': 3,\n",
       " 'snells': 3,\n",
       " 'onotation': 3,\n",
       " 'jura': 3,\n",
       " 'datasheets': 3,\n",
       " 'magnification': 3,\n",
       " 'lasers2': 3,\n",
       " 'labcourse': 3,\n",
       " 'ther': 3,\n",
       " 'nonspatial': 3,\n",
       " 'satisfied': 3,\n",
       " 'workability': 3,\n",
       " 'immobilization': 3,\n",
       " 'channels5': 3,\n",
       " 'inherited': 3,\n",
       " 'gasphase': 3,\n",
       " 'hexa': 3,\n",
       " 'crowd': 3,\n",
       " 'persona': 3,\n",
       " 'orlando': 3,\n",
       " 'biothermodynamics': 3,\n",
       " 'yearly': 3,\n",
       " 'UART': 3,\n",
       " 'interfaces5': 3,\n",
       " 'fleisher': 3,\n",
       " 'crustal': 3,\n",
       " 'rnabased': 3,\n",
       " 'soap': 3,\n",
       " 'disassemble': 3,\n",
       " 'subtypes': 3,\n",
       " 'sampler': 3,\n",
       " 'biochemicalbiological': 3,\n",
       " 'problems12': 3,\n",
       " 'vant': 3,\n",
       " 'geochemistry': 3,\n",
       " 'inadequate': 3,\n",
       " 'partnership': 3,\n",
       " 'marginalization': 3,\n",
       " 'wetland': 3,\n",
       " 'stratification': 3,\n",
       " 'behave': 3,\n",
       " 'munarin': 3,\n",
       " 'etc5': 3,\n",
       " 'dedication': 3,\n",
       " 'supplied': 3,\n",
       " 'vera': 3,\n",
       " 'synthesis3': 3,\n",
       " 'attributed': 3,\n",
       " 'laureate': 3,\n",
       " 'valuetheorem': 3,\n",
       " 'wormlike': 3,\n",
       " 'integrability': 3,\n",
       " 'fitout': 3,\n",
       " 'PSK': 3,\n",
       " 'mezzanine': 3,\n",
       " 'SANS': 3,\n",
       " 'VSEPR': 3,\n",
       " 'electromotive': 3,\n",
       " 'factorial': 3,\n",
       " 'embeded': 3,\n",
       " 'httpmoodleepflchcourseviewphpid3671': 3,\n",
       " 'rootcause': 3,\n",
       " 'rearranged': 3,\n",
       " 'majeurs': 3,\n",
       " 'metabolism7': 3,\n",
       " 'caseof': 3,\n",
       " 'tree4': 3,\n",
       " 'layering': 3,\n",
       " 'CSR': 3,\n",
       " 'EXAMINATION': 3,\n",
       " 'ksat12': 3,\n",
       " 'refers': 3,\n",
       " 'correspondent': 3,\n",
       " 'fusion2': 3,\n",
       " 'courjault': 3,\n",
       " 'freeradical': 3,\n",
       " 'httpwwwdouloscomknowhowvhdldesignersguidehttpwwwdouloscomknowhowsysveriloghttpwwwdouloscomknowhowsystemc': 3,\n",
       " 'landolt': 3,\n",
       " 'accept': 3,\n",
       " 'patienttherapistoriented': 3,\n",
       " 'httpwwwsp4commorg': 3,\n",
       " 'autonomy': 3,\n",
       " 'constructed': 3,\n",
       " 'mucosal': 3,\n",
       " 'analized': 3,\n",
       " 'isues': 3,\n",
       " 'andregulation': 3,\n",
       " 'workprinciple': 3,\n",
       " 'monomer': 3,\n",
       " 'internalizing': 3,\n",
       " 'exploratory': 3,\n",
       " 'forthe': 3,\n",
       " 'expects': 3,\n",
       " 'deembedding': 3,\n",
       " 'rewritingbased': 3,\n",
       " 'photoresists': 3,\n",
       " 'Q': 3,\n",
       " 'nanomanipulation': 3,\n",
       " 'CS107': 3,\n",
       " 'espionage': 3,\n",
       " 'ah2describe': 3,\n",
       " 'openness': 3,\n",
       " 'semaphor': 3,\n",
       " 'untapped': 3,\n",
       " 'ar201c': 3,\n",
       " 'photons2': 3,\n",
       " 'wavlength': 3,\n",
       " 'edpsciences': 3,\n",
       " 'potentiality': 3,\n",
       " 'excatrhedra': 3,\n",
       " 'highpass': 3,\n",
       " 'zvi': 3,\n",
       " 'celine': 3,\n",
       " 'lasers41': 3,\n",
       " 'mesurands': 3,\n",
       " 'FSM': 3,\n",
       " 'MICRO330': 3,\n",
       " 'kepler': 3,\n",
       " 'generationrecombination': 3,\n",
       " 'membersa': 3,\n",
       " 'feedforward': 3,\n",
       " 'HEPA': 3,\n",
       " 'siting': 3,\n",
       " 'chemosphere': 3,\n",
       " 'prob': 3,\n",
       " 'dominated': 3,\n",
       " 'twelve': 3,\n",
       " 'ah29perform': 3,\n",
       " 'itraqtmt': 3,\n",
       " 'aronson': 3,\n",
       " 'labvisits': 3,\n",
       " 'oceanography': 3,\n",
       " 'feasible': 3,\n",
       " 'tractable': 3,\n",
       " 'toxicological': 3,\n",
       " 'examples4th': 3,\n",
       " 'filtres': 3,\n",
       " 'counterdiffusion': 3,\n",
       " 'divertor': 3,\n",
       " 'ah11link': 3,\n",
       " 'blackandwhite': 3,\n",
       " 'profitable': 3,\n",
       " 'E19': 3,\n",
       " 'netword': 3,\n",
       " 'motility3': 3,\n",
       " 'opv': 3,\n",
       " 'economicsâ\\x80\\x99': 3,\n",
       " 'quartic': 3,\n",
       " 'inconsistent': 3,\n",
       " 'spacetimeefficient': 3,\n",
       " 'remedy': 3,\n",
       " 'neufville': 3,\n",
       " 'massproduction': 3,\n",
       " 'monument': 3,\n",
       " 'basketweave': 3,\n",
       " 'writen': 3,\n",
       " 'biopharmaceuticals': 3,\n",
       " 'pattaroni': 3,\n",
       " 'newmann': 3,\n",
       " 'asbuilt': 3,\n",
       " 'availability3': 3,\n",
       " 'pressuriseg': 3,\n",
       " 'spectroscopythermal': 3,\n",
       " 'CAVE': 3,\n",
       " 'HETP': 3,\n",
       " 'PEAQ': 3,\n",
       " 'nanoscaled': 3,\n",
       " 'twopage': 3,\n",
       " 'E12': 3,\n",
       " 'electronicstructure': 3,\n",
       " 'acqusition': 3,\n",
       " 'backanalysis': 3,\n",
       " 'rf': 3,\n",
       " 'agentslanthanidesactinidescoordination': 3,\n",
       " 'multijunction': 3,\n",
       " 'INO': 3,\n",
       " 'anddevelop': 3,\n",
       " 'interafce': 3,\n",
       " 'AISC34110': 3,\n",
       " 'artery': 3,\n",
       " 'scopus': 3,\n",
       " 'subtransmission': 3,\n",
       " 'bruus': 3,\n",
       " 'mediumsized': 3,\n",
       " 'freqon': 3,\n",
       " 'stressful': 3,\n",
       " 'pharma': 3,\n",
       " 'ah1link': 3,\n",
       " 'propagationiv': 3,\n",
       " 'pressurevelocity': 3,\n",
       " 'counterintuitive': 3,\n",
       " 'ah11state': 3,\n",
       " 'firstyear': 3,\n",
       " 'eyer': 3,\n",
       " 'transistorlevel': 3,\n",
       " 'oversampling': 3,\n",
       " 'geneva9': 3,\n",
       " 'transferfunction': 3,\n",
       " 'fondamentaux': 3,\n",
       " 'looked': 3,\n",
       " 'BIOENG437': 3,\n",
       " 'proximity': 3,\n",
       " 'KPI': 3,\n",
       " 'symmetryrelated': 3,\n",
       " 'multiview': 3,\n",
       " 'highspecialized': 3,\n",
       " 'conditions2': 3,\n",
       " 'cp6choose': 3,\n",
       " 'JMLR': 3,\n",
       " 'educate': 3,\n",
       " 'CH405': 3,\n",
       " 'entanglement': 3,\n",
       " 'twinned': 3,\n",
       " 'counterpart': 3,\n",
       " 'httpsvepflchfilescontentsitessvnew2filessharedisrecpdfgraceisrec20lectures20202016pdf': 3,\n",
       " 'CS101': 3,\n",
       " 'practicaloriented': 3,\n",
       " 'introdution': 3,\n",
       " 'ignition': 3,\n",
       " 'VLIW': 3,\n",
       " 'pack': 3,\n",
       " 'gruettermri': 3,\n",
       " 'AMRWB': 3,\n",
       " 'hypersensitive': 3,\n",
       " 'SNOM': 3,\n",
       " 'bigio': 3,\n",
       " 'snowpackformulate': 3,\n",
       " 'lumped': 3,\n",
       " 'UMP': 3,\n",
       " 'calculated': 3,\n",
       " 'elicit': 3,\n",
       " 'hernia': 3,\n",
       " 'abvariable': 3,\n",
       " 'compiled': 3,\n",
       " 'majority': 3,\n",
       " 'inorganc': 3,\n",
       " 'feedbacksolving': 3,\n",
       " 'enact': 3,\n",
       " 'predatorprey': 3,\n",
       " 'stressed': 3,\n",
       " 'photoconductors': 3,\n",
       " 'PGP': 3,\n",
       " 'corentin': 3,\n",
       " 'synthesizing': 3,\n",
       " 'csi': 3,\n",
       " 'diagnostic5': 3,\n",
       " 'collaborates': 3,\n",
       " 'B11': 3,\n",
       " 'intractable': 3,\n",
       " 'chisquared': 3,\n",
       " 'interfirm': 3,\n",
       " 'datajudge': 3,\n",
       " 'preparatory': 3,\n",
       " 'metalcatalysis': 3,\n",
       " 'timedependant': 3,\n",
       " 'WSL': 3,\n",
       " 'JFA': 3,\n",
       " 'vein': 3,\n",
       " 'borrowed': 3,\n",
       " 'paralell': 3,\n",
       " 'interconnectionsynchronization': 3,\n",
       " 'scien\\xadti\\xadfic': 3,\n",
       " 'realizing': 3,\n",
       " 'lietrature': 3,\n",
       " 'turbo': 3,\n",
       " 'bioremediation': 3,\n",
       " 'CAE': 3,\n",
       " 'observable': 3,\n",
       " 'taleba': 3,\n",
       " 'significantly': 3,\n",
       " 'respiration': 3,\n",
       " 'vol38': 3,\n",
       " 'flagellum': 3,\n",
       " 'eschenmoser': 3,\n",
       " 'prion': 3,\n",
       " 'strait': 3,\n",
       " 'measurments': 3,\n",
       " 'metabolism8': 3,\n",
       " 'berlindr': 3,\n",
       " 'committee': 3,\n",
       " 'beamforming': 3,\n",
       " 'tablet': 3,\n",
       " 'norman': 3,\n",
       " 'altogether': 3,\n",
       " 'appendage': 3,\n",
       " 'writeoncereadmany': 3,\n",
       " 'ROI': 3,\n",
       " 'formalise': 3,\n",
       " 'precession': 3,\n",
       " 'buil': 3,\n",
       " 'httpwwwmitrplodzplevulectures': 3,\n",
       " 'suisse': 3,\n",
       " 'eppinger': 3,\n",
       " 'BRST': 3,\n",
       " 'elucidating': 3,\n",
       " 'cleaning': 3,\n",
       " 'hyphenated': 3,\n",
       " 'environomic': 3,\n",
       " 'micromechanisms': 3,\n",
       " 'demurtasa': 3,\n",
       " 'determinism': 3,\n",
       " 'ebeams': 3,\n",
       " 'referenceframe': 3,\n",
       " 'methods4': 3,\n",
       " 'wisconsin': 3,\n",
       " 'manfred': 3,\n",
       " 'manufacturingtechniques': 3,\n",
       " 'gpsspectral': 3,\n",
       " 'systèmesonchip': 3,\n",
       " 'nanolithography': 3,\n",
       " 'michler': 3,\n",
       " 'HENRY': 3,\n",
       " 'sessions1': 3,\n",
       " 'TCB': 3,\n",
       " 'intermediaries7': 3,\n",
       " 'allostery': 3,\n",
       " 'einsteinstokes': 3,\n",
       " 'interferomety': 3,\n",
       " 'preperation': 3,\n",
       " 'wildtype': 3,\n",
       " 'ivo': 3,\n",
       " 'persuasive': 3,\n",
       " 'helioseismology': 3,\n",
       " 'bandshift': 3,\n",
       " 'digaonalization': 3,\n",
       " 'doesnt': 3,\n",
       " 'gachet': 3,\n",
       " 'rayon': 3,\n",
       " 'lumetric': 3,\n",
       " 'dnabased': 3,\n",
       " 'yamabe': 3,\n",
       " 'enjoyability': 3,\n",
       " 'FCS': 3,\n",
       " 'frugal': 3,\n",
       " 'cysteine': 3,\n",
       " 'hydrostatics': 3,\n",
       " 'opentext': 3,\n",
       " 'arnell': 3,\n",
       " 'oksendal': 3,\n",
       " 'RESEARCH': 3,\n",
       " 'eye3': 3,\n",
       " 'transcriptional': 3,\n",
       " 'httplcvmwwwepflchcgdna': 3,\n",
       " 'viganò': 3,\n",
       " 'GGA8': 3,\n",
       " 'questioning': 3,\n",
       " 'collaborate': 3,\n",
       " 'lidaronchip': 3,\n",
       " 'liouvillespace': 3,\n",
       " 'diffraction41': 3,\n",
       " 'bilateral': 3,\n",
       " 'baum': 3,\n",
       " 'timer': 3,\n",
       " 'antifragility': 3,\n",
       " 'began': 3,\n",
       " 'unnatural': 3,\n",
       " 'channeling': 3,\n",
       " 'microct': 3,\n",
       " 'jantsch': 3,\n",
       " 'homeostasisregeneration': 3,\n",
       " 'DIBL': 3,\n",
       " 'socioeconomical': 3,\n",
       " 'MATH407': 3,\n",
       " 'MPEG21': 3,\n",
       " 'synchonization': 3,\n",
       " 'deployed': 3,\n",
       " 'operation10': 3,\n",
       " 'consulter': 3,\n",
       " 'STUDIO': 3,\n",
       " 'AO': 3,\n",
       " 'replacement': 3,\n",
       " 'stated': 3,\n",
       " 'prolog': 3,\n",
       " 'ultrashallow': 3,\n",
       " 'differentiationcommitment': 3,\n",
       " 'hysicochemical': 3,\n",
       " 'stoechiometric': 3,\n",
       " 'piezoelectrics5': 3,\n",
       " 'biomineralization6': 3,\n",
       " 'propopsed': 3,\n",
       " 'dorling': 3,\n",
       " 'roland': 3,\n",
       " 'tensentence': 3,\n",
       " 'insulator': 3,\n",
       " 'stemming': 3,\n",
       " 'evasion': 3,\n",
       " 'pleasure': 3,\n",
       " 'domaine': 3,\n",
       " 'polymers6': 3,\n",
       " 'ndphysique': 3,\n",
       " 'securitization': 3,\n",
       " 'incentives6': 3,\n",
       " 'dental': 3,\n",
       " 'biomechanical': 3,\n",
       " 'outperform': 3,\n",
       " 'electronnuclear': 3,\n",
       " 'collagen': 3,\n",
       " 'UMTSHSDPA': 3,\n",
       " 'canoe': 3,\n",
       " 'neurobiology': 3,\n",
       " 'AMP': 3,\n",
       " 'wishing': 3,\n",
       " 'tansforms': 3,\n",
       " 'behra': 3,\n",
       " 'triaxial': 3,\n",
       " 'transportcompensation': 3,\n",
       " 'diffuser': 3,\n",
       " 'electromechanics8': 3,\n",
       " 'librarian': 3,\n",
       " 'cole': 3,\n",
       " 'lactones': 3,\n",
       " 'soundness': 3,\n",
       " 'substates': 3,\n",
       " 'topi': 3,\n",
       " 'commont': 3,\n",
       " 'effects5': 3,\n",
       " 'CV': 3,\n",
       " 'nonreactive': 3,\n",
       " 'builiding': 3,\n",
       " 'relativevalue': 3,\n",
       " 'assenbly': 3,\n",
       " 'sequentialsynchronous': 3,\n",
       " 'id': 3,\n",
       " 'progressively': 3,\n",
       " 'predominantly': 3,\n",
       " 'pluralism': 3,\n",
       " 'sensing5': 3,\n",
       " 'MATH111': 3,\n",
       " 'modularity': 3,\n",
       " 'interspeaker': 3,\n",
       " 'lieb': 3,\n",
       " 'processes8': 3,\n",
       " 'surfacemodified': 3,\n",
       " 'clusteringd': 3,\n",
       " 'intramolecular': 3,\n",
       " 'subtraction': 3,\n",
       " 'duda': 3,\n",
       " 'type2': 3,\n",
       " 'insensibility': 3,\n",
       " 'modelsdatamining': 3,\n",
       " 'shell': 3,\n",
       " 'shortessay': 3,\n",
       " 'stiction': 3,\n",
       " 'REST': 3,\n",
       " 'SOSP': 3,\n",
       " 'ah25describe': 3,\n",
       " 'amplifying': 3,\n",
       " 'capitalist': 3,\n",
       " 'metallatedligands': 3,\n",
       " 'sheaf': 3,\n",
       " 'materialsphysics': 3,\n",
       " 'sizable': 3,\n",
       " 'creepand': 3,\n",
       " 'routinely': 3,\n",
       " 'pseudoreplications': 3,\n",
       " 'environnment': 3,\n",
       " 'recruitment': 3,\n",
       " 'decompostitions': 3,\n",
       " 'retrieve': 3,\n",
       " 'lightweight': 3,\n",
       " 'ck': 3,\n",
       " 'development5': 3,\n",
       " 'piston': 3,\n",
       " 'electricityproducing': 3,\n",
       " 'representativity': 3,\n",
       " 'touristic': 3,\n",
       " 'EFPL': 3,\n",
       " 'miniature': 3,\n",
       " 'telematics': 3,\n",
       " 'polarizers': 3,\n",
       " 'diego': 3,\n",
       " 'hematopoiesis': 3,\n",
       " 'ru': 3,\n",
       " 'orthopedics': 3,\n",
       " 'AISC35810': 3,\n",
       " 'publish': 3,\n",
       " 'EAWS': 3,\n",
       " 'perceiving': 3,\n",
       " 'cp5formulate': 3,\n",
       " 'BA2': 3,\n",
       " 'micro331': 3,\n",
       " 'analyzelisten': 3,\n",
       " 'intact': 3,\n",
       " 'pursuit': 3,\n",
       " 'perfusion': 3,\n",
       " 'corte': 3,\n",
       " 'abilty': 3,\n",
       " 'EVER': 3,\n",
       " 'inksubstrate': 3,\n",
       " 'tribocorrosion': 3,\n",
       " 'actuators6': 3,\n",
       " 'multiplicative': 3,\n",
       " 'opened': 3,\n",
       " 'cyclesspecifics': 3,\n",
       " 'bump': 3,\n",
       " 'thiophene': 3,\n",
       " 'alkaline': 3,\n",
       " 'examples3': 3,\n",
       " 'nanotoxicological': 3,\n",
       " 'TURCHI': 3,\n",
       " 'zippel': 3,\n",
       " 'ibn': 3,\n",
       " 'httpmoodleepflchcourseenrolphpid9371': 3,\n",
       " 'lo': 3,\n",
       " 'lebesgu': 3,\n",
       " 'runner': 3,\n",
       " 'aspectsphysical': 3,\n",
       " 'tropospheric': 3,\n",
       " 'ford': 3,\n",
       " 'clausing': 3,\n",
       " 'doubling': 3,\n",
       " 'phosphate': 3,\n",
       " 'anodic': 3,\n",
       " 'control40': 3,\n",
       " 'involvment': 3,\n",
       " 'peridoic': 3,\n",
       " 'learing': 3,\n",
       " 'ghetto': 3,\n",
       " 'regimeii': 3,\n",
       " 'biodegradable': 3,\n",
       " 'BROTTON': 3,\n",
       " 'replicating': 3,\n",
       " 'model7': 3,\n",
       " 'PWM': 3,\n",
       " 'psychometric': 3,\n",
       " 'DAY': 3,\n",
       " 'invertebrate': 3,\n",
       " 'editor': 3,\n",
       " 'steganography': 3,\n",
       " 'schemessuch': 3,\n",
       " 'FTCM': 3,\n",
       " 'partof': 3,\n",
       " 'characterise': 3,\n",
       " 'SETS': 3,\n",
       " 'byzantine': 3,\n",
       " 'tf': 3,\n",
       " 'HMMANN': 3,\n",
       " 'A5': 3,\n",
       " 'reductionof': 3,\n",
       " 'milli': 3,\n",
       " 'pioneer': 3,\n",
       " 'ethylene': 3,\n",
       " 'villette': 3,\n",
       " 'moses': 3,\n",
       " 'transitionsexcited': 3,\n",
       " 'modulationdemodulation': 3,\n",
       " 'veterinary': 3,\n",
       " 'ITU6': 3,\n",
       " 'biorefineries': 3,\n",
       " 'birkhäuser': 3,\n",
       " 'nanoelectronic': 3,\n",
       " 'neuchâtel': 3,\n",
       " 'httpmoodleepflchcourseviewphpid378': 3,\n",
       " 'infomation': 3,\n",
       " 'latestage': 3,\n",
       " 'effortful': 3,\n",
       " 'AKERMAN': 3,\n",
       " 'termal': 3,\n",
       " 'proliferation': 3,\n",
       " 'fetal': 3,\n",
       " 'poincares': 3,\n",
       " 'reservation': 3,\n",
       " 'uncontrolled': 3,\n",
       " 'broadly': 3,\n",
       " 'MSE231': 3,\n",
       " 'warmkessel': 3,\n",
       " 'splicing': 3,\n",
       " 'sanitaire': 3,\n",
       " 'operationsbe': 3,\n",
       " 'CJ': 3,\n",
       " 'crystals3': 3,\n",
       " 'nanotribology': 3,\n",
       " 'hardline': 3,\n",
       " 'semconductors': 3,\n",
       " 'coherence12': 3,\n",
       " 'configurable': 3,\n",
       " 'provenance': 3,\n",
       " 'eigenstates': 3,\n",
       " 'informationtheoretic': 3,\n",
       " 'andrew': 3,\n",
       " 'protected': 3,\n",
       " 'restauration': 3,\n",
       " 'liquefaction': 3,\n",
       " 'max40': 3,\n",
       " 'wormalds': 3,\n",
       " 'biotatalysis': 3,\n",
       " 'scraper': 3,\n",
       " 'embarassingly': 3,\n",
       " 'bloodvessel': 3,\n",
       " 'imaginarytime': 3,\n",
       " 'thematics': 3,\n",
       " 'discrimination': 3,\n",
       " 'ferroelastic': 3,\n",
       " 'disscued': 3,\n",
       " 'estimation4': 3,\n",
       " 'antagonism': 3,\n",
       " 'fluidics': 3,\n",
       " 'markup': 3,\n",
       " 'ah1describe': 3,\n",
       " 'bitinterleaved': 3,\n",
       " 'phosphorene': 3,\n",
       " 'july': 3,\n",
       " 'TRIBOLOGY': 3,\n",
       " 'highimpact': 3,\n",
       " 'decidability': 3,\n",
       " 'eaxam': 3,\n",
       " 'elastoplasticity': 3,\n",
       " 'kindersley': 3,\n",
       " 'backscatter': 3,\n",
       " 'lockfree': 3,\n",
       " 'metabolites3': 3,\n",
       " 'designflow': 3,\n",
       " 'dinner': 3,\n",
       " 'gross': 3,\n",
       " 'ciruits': 3,\n",
       " 'drainage': 3,\n",
       " 'tuned': 3,\n",
       " 'processes3rd': 3,\n",
       " 'ruines': 3,\n",
       " 'photochemisty': 3,\n",
       " 'copying': 3,\n",
       " 'MICRO102': 3,\n",
       " 'digest': 3,\n",
       " 'flask': 3,\n",
       " 'substances4': 3,\n",
       " 'MM': 3,\n",
       " 'practicebased': 3,\n",
       " 'repeat': 3,\n",
       " 'stokey': 3,\n",
       " 'linecamera': 3,\n",
       " 'derivatives8': 3,\n",
       " 'rpesentations': 3,\n",
       " 'BH': 3,\n",
       " 'pathological': 3,\n",
       " 'phyics': 3,\n",
       " 'argumentstensors': 3,\n",
       " 'classmate': 3,\n",
       " 'cooperative': 3,\n",
       " 'lifesciences': 3,\n",
       " 'surfing': 3,\n",
       " 'rockwell': 3,\n",
       " 'biotopes': 3,\n",
       " 'interscience': 3,\n",
       " 'sun': 3,\n",
       " 'coatingsubstrate': 3,\n",
       " 'gehrys': 3,\n",
       " 'properties6': 3,\n",
       " 'reactiondesorption': 3,\n",
       " 'nondissipative': 3,\n",
       " 'scientificgrade': 3,\n",
       " 'marsicano': 3,\n",
       " 'formalisation9': 3,\n",
       " 'enigma': 3,\n",
       " 'inpractical': 3,\n",
       " 'hystorically': 3,\n",
       " 'lola': 3,\n",
       " 'tsvs': 3,\n",
       " 'photosensor': 3,\n",
       " 'variableselection': 3,\n",
       " 'andmethods': 3,\n",
       " 'predesign': 3,\n",
       " 'merino': 3,\n",
       " 'compatible': 3,\n",
       " 'statespacecontrol': 3,\n",
       " 'regolators': 3,\n",
       " 'photomultipliers': 3,\n",
       " 'VC': 3,\n",
       " 'sébastien': 3,\n",
       " 'highq': 3,\n",
       " 'pricing4': 3,\n",
       " 'dropondemand': 3,\n",
       " 'PI': 3,\n",
       " 'AIAA20046012': 3,\n",
       " 'clausius': 3,\n",
       " 'santos': 3,\n",
       " 'mack': 3,\n",
       " 'drought': 3,\n",
       " 'demandsupply': 3,\n",
       " 'morton': 3,\n",
       " 'hayashi': 3,\n",
       " 'pinterest': 3,\n",
       " 'distributionevaluate': 3,\n",
       " 'cumputer': 3,\n",
       " 'solary': 3,\n",
       " 'auto': 3,\n",
       " 'equatorial': 3,\n",
       " 'unfired': 3,\n",
       " 'thermo': 3,\n",
       " 'fluidised': 3,\n",
       " 'sectional': 3,\n",
       " 'triazole': 3,\n",
       " 'OSVVM': 3,\n",
       " 'dbmsdesign': 3,\n",
       " 'passage': 3,\n",
       " 'knearest': 3,\n",
       " 'httpclickersepflchstudents': 3,\n",
       " 'wont': 3,\n",
       " 'brisken': 3,\n",
       " 'sodium': 3,\n",
       " 'practicesâ\\x80\\x9d': 3,\n",
       " 'portofolio': 3,\n",
       " '300CHF': 3,\n",
       " 'steepest': 3,\n",
       " 'avellan': 3,\n",
       " 'comapny': 3,\n",
       " 'actionsynthesize': 3,\n",
       " 'planning33': 3,\n",
       " 'unilever': 3,\n",
       " 'ceramicmetalglass': 3,\n",
       " 'fractional': 3,\n",
       " 'confinementiii': 3,\n",
       " 'metalcentered': 3,\n",
       " 'hamm': 3,\n",
       " 'nanosystem': 3,\n",
       " 'approriate': 3,\n",
       " 'articlebased': 3,\n",
       " 'transconductance': 3,\n",
       " 'zirconium': 3,\n",
       " 'DF': 3,\n",
       " 'lexical': 3,\n",
       " 'solidelectrolyte': 3,\n",
       " 'realizable': 3,\n",
       " 'flo': 3,\n",
       " 'lucas': 3,\n",
       " 'contintuity': 3,\n",
       " 'scènes': 3,\n",
       " 'moisture': 3,\n",
       " 'cytokine': 3,\n",
       " 'downconversion': 3,\n",
       " '36010AISC': 3,\n",
       " 'NIHS': 3,\n",
       " 'gnerative': 3,\n",
       " 'overcome': 3,\n",
       " 'abuse': 3,\n",
       " 'efficency': 3,\n",
       " 'lamination': 3,\n",
       " 'nonlti3': 3,\n",
       " 'landmarkbased': 3,\n",
       " 'superlattices': 3,\n",
       " 'restraint': 3,\n",
       " 'randomised': 3,\n",
       " 'hosted': 3,\n",
       " 'queen': 3,\n",
       " 'enbedded': 3,\n",
       " 'robotica': 3,\n",
       " 'chalcogenide': 3,\n",
       " 'writer': 3,\n",
       " 'mandelbrot': 3,\n",
       " 'cooccurrence': 3,\n",
       " 'semicustom': 3,\n",
       " 'biblio': 3,\n",
       " 'MICRO455': 3,\n",
       " 'macroscale': 3,\n",
       " 'phonetic': 3,\n",
       " 'actuating': 3,\n",
       " 'sommerfeld': 3,\n",
       " 'chrystallography': 3,\n",
       " 'quasar': 3,\n",
       " 'tenet': 3,\n",
       " 'robustly': 3,\n",
       " 'infusionmsms': 3,\n",
       " 'photostability4': 3,\n",
       " 'shelflife': 3,\n",
       " 'meibom': 3,\n",
       " 'positioning4': 3,\n",
       " 'hutchings': 3,\n",
       " 'cartographer': 3,\n",
       " 'andy': 3,\n",
       " 'mol': 3,\n",
       " 'materials5': 3,\n",
       " 'leadtime': 3,\n",
       " 'hardcore': 3,\n",
       " 'engaged': 3,\n",
       " 'MSE203': 3,\n",
       " 'limp': 3,\n",
       " 'artin': 3,\n",
       " 'lecures': 3,\n",
       " 'addons': 3,\n",
       " 'developme': 3,\n",
       " 'CS452': 3,\n",
       " 'demarchi': 3,\n",
       " 'esp': 3,\n",
       " 'haskell': 3,\n",
       " 'ah28analyze': 3,\n",
       " 'chaize': 3,\n",
       " 'und': 3,\n",
       " 'physicalchemical': 3,\n",
       " 'CBCM': 3,\n",
       " 'chargedipole': 3,\n",
       " 'publisher': 3,\n",
       " 'prototyped': 3,\n",
       " 'polyurethane': 3,\n",
       " 'conformal': 3,\n",
       " 'sony': 3,\n",
       " 'elementsmagnetic': 3,\n",
       " 'databasesearch': 3,\n",
       " 'hoare': 3,\n",
       " 'alain': 3,\n",
       " 'supplies4': 3,\n",
       " 'EE350': 3,\n",
       " 'meylan': 3,\n",
       " 'warren': 3,\n",
       " 'falling': 3,\n",
       " 'ah11work': 3,\n",
       " 'openly': 3,\n",
       " 'HUM417': 3,\n",
       " 'channels4': 3,\n",
       " 'portrait': 3,\n",
       " 'solidcatalyzed': 3,\n",
       " 'socioeconomis': 3,\n",
       " 'cholinergic': 3,\n",
       " 'inthe': 3,\n",
       " 'hoc': 3,\n",
       " 'PM': 3,\n",
       " 'rodogno': 3,\n",
       " 'deflection': 3,\n",
       " 'hemaotopoietic': 3,\n",
       " 'mut': 3,\n",
       " 'carbocyclization': 3,\n",
       " 'TPCIP': 3,\n",
       " 'dayweek': 3,\n",
       " 'corotational': 3,\n",
       " 'GPR': 3,\n",
       " 'parallelizing': 3,\n",
       " 'atherosclerotic': 3,\n",
       " 'transitors': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(globalBagOfWords,key=globalBagOfWords.get)\n",
    "dict(sorted(globalBagOfWords.items(), key=operator.itemgetter(1), reverse=False)[:5000])\n",
    "# Maybe discard only the 3 most used words? since system and design are more specific than learning, student and system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test sample of courses (just the first 3)\n",
    "sampleCourses = [{'courseId': 'MSC-101',\n",
    "  'description': \"Here comes the sun, dudududu, here comes the sun and I say...\",\n",
    "  'name': 'The Beatles'},\n",
    "                 {'courseId': 'MSC-102',\n",
    "  'description': \"In an octupus's garden, in the sea. He'd let us in...\",\n",
    "  'name': 'The Beatles Too'},\n",
    "                 {'courseId': 'MSC-103',\n",
    "    'description': \"Born, to be wiiiiild dudududu\",\n",
    "    'name': 'Steppenwolf'}]\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'octupuss': 1, 'I': 1, 'sea': 1, 'hed': 1, 'sun': 2, 'dudududu': 1, 'garden': 1}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "sampleGlobalBagOfWords = {}\n",
    "sampleGlobalBagOfWords = getGlobalBagOfWords(sampleCourses)\n",
    "print(sampleGlobalBagOfWords)\n",
    "print(sum(sampleGlobalBagOfWords.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'octupuss': 1, 'I': 1, 'sea': 1, 'hed': 1, 'sun': 2, 'dudududu': 1, 'garden': 1}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "sampleBagOfWords = {}\n",
    "sampleGlobalBagOfWords = {}\n",
    "getBagOfWords(sampleCourses[1]['description'])\n",
    "for course in sampleCourses:\n",
    "    sampleBow = getBagOfWords(course['description'])\n",
    "    sampleBagOfWords[course['courseId']] = sampleBow\n",
    "    mergeBow(sampleGlobalBagOfWords,sampleBow)\n",
    "#test_course = sampleCourses.copy()\n",
    "#print(sampleBagOfWords)\n",
    "print(sampleGlobalBagOfWords)\n",
    "#print(sum(sampleBagOfWords.values()))\n",
    "print(sum(sampleGlobalBagOfWords.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#courses\n",
    "#globalBagOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Term Document Matrix\n",
    "# We want a matrix where each row i is a word (among global bag of words) \n",
    "# and each column j is a document (among all courses)\n",
    "# tdm[i][j] = nb of occurences of term i in doc j\n",
    "\n",
    "def getTermDocMatrix(courses):\n",
    "    \n",
    "    # get global bag of word (for all courses combined) \n",
    "    globalBagOfWord = getGlobalBagOfWords(courses)\n",
    "    \n",
    "    # total number of terms\n",
    "    M = len(globalBagOfWord)\n",
    "\n",
    "    # total number of documents\n",
    "    N = len(courses)\n",
    "\n",
    "    termDocMatrix = np.zeros((M,N), dtype=np.int)\n",
    "\n",
    "    # Column index\n",
    "    docIndx = 0\n",
    "\n",
    "    for doc in courses: \n",
    "        bow = getBagOfWords(doc['description'])\n",
    "        # Row index\n",
    "        termIndx = 0\n",
    "        for word in globalBagOfWord.keys():\n",
    "            termDocMatrix[termIndx][docIndx] += bow.get(word, 0)\n",
    "            termIndx += 1\n",
    "        docIndx += 1\n",
    "    return termDocMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [2 0]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getTermFrequency' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-68a3395eaf2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetTermDocMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetTermFrequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetInverseDocFrequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getTermFrequency' is not defined"
     ]
    }
   ],
   "source": [
    "print(getTermDocMatrix(sampleCourses))\n",
    "print(getTermFrequency(sampleCourses))\n",
    "print(getImportance(sampleCourses))\n",
    "print(getInverseDocFrequency(sampleCourses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute fij (frequency of term i in doc j), à transformer en fonction?\n",
    "\n",
    "def getTermFrequency(courses):\n",
    "    # get global bag of word (for all courses combined) \n",
    "    globalBagOfWord = getGlobalBagOfWords(courses)\n",
    "\n",
    "    totalWords = len(globalBagOfWord)\n",
    "    totalCourses = len(courses)\n",
    "\n",
    "    f = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "\n",
    "    docIndx = 0\n",
    "    for doc in courses:\n",
    "        bow = getBagOfWords(doc['description'])\n",
    "        wordIndx = 0\n",
    "        for word in bow:\n",
    "            f[wordIndx][docIndx] = bow.get(word,0) / len(bow) \n",
    "            wordIndx += 1\n",
    "        docIndx += 1\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute TFij \"importance of word i in doc j\"\n",
    "def getImportance(courses):\n",
    "    # get global bag of word (for all courses combined) \n",
    "    globalBagOfWord = getGlobalBagOfWords(courses)\n",
    "\n",
    "    totalWords = len(globalBagOfWord)\n",
    "    totalCourses = len(courses)\n",
    "    \n",
    "    TF = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "    maxWordOfDoc = [\"\"]*totalCourses\n",
    "    \n",
    "    # Compute term frequency\n",
    "    f = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "    f = getTermFrequency(courses)\n",
    "    \n",
    "    # Find the number of occurences of the most used words in every document\n",
    "    docIndx = 0\n",
    "    for doc in courses:\n",
    "        bow = getBagOfWords(doc['description'])\n",
    "        maxWordOfDoc[docIndx] = list(bow.values())[np.argmax(f[docIndx])]\n",
    "        docIndx += 1\n",
    "\n",
    "    # Compute TF\n",
    "    # Note: on a pas besoin d'itérer sur toutes les lignes, juste les colonnes mais j'arrive pas à utiliser \n",
    "    # la fonction np.apply_along_axis en passant une fonction qui doit connaitre l'indice de la ligne\n",
    "    for i in range(totalWords):\n",
    "        for j in range(totalCourses):\n",
    "            TF[i][j] = f[i][j] / maxWordOfDoc[j]\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inverse Document Frequency : IDF\n",
    "# Compute n[i] = nb of documents where word i occurs at least once\n",
    "def getInverseDocFrequency(courses):\n",
    "    # get global bag of word (for all courses combined) \n",
    "    globalBagOfWord = getGlobalBagOfWords(courses)\n",
    "    totalWords = len(globalBagOfWord)\n",
    "    totalCourses = len(courses)\n",
    "\n",
    "    # Compute term frequency\n",
    "    f = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "    f = getTermFrequency(courses)\n",
    "    \n",
    "    n = np.zeros((totalWords),dtype=np.int)\n",
    "    IDF = np.zeros((totalWords),dtype=np.double)\n",
    "\n",
    "    for i in range(totalWords):\n",
    "        for j in range(totalCourses):\n",
    "            if(f[i][j] != 0):\n",
    "                n[i] += 1\n",
    "        if(n[i] == 0):\n",
    "            IDF[i] = 0\n",
    "        else:\n",
    "            IDF[i] = -math.log2(n[i]/totalCourses)\n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.  ]\n",
      " [-0.   -0.  ]\n",
      " [-0.   -0.  ]\n",
      " [ 0.    0.25]\n",
      " [ 0.    0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Compute TF-IDF score\n",
    "\n",
    "# get global bag of word (for all courses combined) \n",
    "globalBagOfWord = getGlobalBagOfWords(sampleCourses)\n",
    "\n",
    "totalWords = len(globalBagOfWord)\n",
    "totalCourses = len(sampleCourses)\n",
    "\n",
    "# Get term frequency\n",
    "TF = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "TF = getImportance(sampleCourses)\n",
    "\n",
    "# Get inverse document frequency\n",
    "IDF = np.zeros((totalWords),dtype=np.double)\n",
    "IDF = getInverseDocFrequency(sampleCourses)\n",
    "    \n",
    "TFIDF = np.zeros((totalWords,totalCourses),dtype=np.double)\n",
    "\n",
    "# Compute TF-IDF\n",
    "for i in range(totalWords):\n",
    "    for j in range(totalCourses):\n",
    "        TFIDF[i][j] = TF[i][j] * IDF[i]\n",
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the slides:\n",
    "\n",
    "N = total number of documents\n",
    "\n",
    "f[i][j] nb of occurrences of word 𝑖 in doc 𝑗, so bagOfWord(j)[i]\n",
    "\n",
    "tf[i][j] = f[i][j] / max_k f[k][j]\n",
    "\n",
    "idf[i] = -log_2(number of documents where word i occurs at least once / N)\n",
    "\n",
    "tfidf[i][j] = tf[i][j] * idf[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim(doc1, doc2):\n",
    "    return np.dot(np.transpose(doc1), doc2) / (np.linalg.norm(doc1) * np.linalg.norm(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'The Beatles', 'description': 'Here comes the sun, dudududu, here comes the sun and I say...', 'courseId': 'MSC-101'}, {'name': 'The Beatles Too', 'description': \"In an octupus's garden, in the sea. He'd let us in...\", 'courseId': 'MSC-102'}, {'name': 'Steppenwolf', 'description': 'Born, to be wiiiiild dudududu', 'courseId': 'MSC-103'}]\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [2 0 0]\n",
      " [1 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23570226039551587"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sampleCourses)\n",
    "tdc = getTermDocMatrix(sampleCourses)\n",
    "print(tdc)\n",
    "sim(tdc[:,0], tdc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
